# arXiv Papers — 2026-02-25

*18 papers across 6 queries.*

## The JWST Resolved Stellar Populations Early Release Science Program. IX. The RR Lyrae Population in WLM with HST and JWST
**Authors:** Catherine M. Slaughter, Evan D. Skillman, Alessandro Savino  
**Query:** autonomous agents open source  
**URL:** http://arxiv.org/abs/2602.21205v1

RR Lyrae stars are a common, dependable Population II distance indicator, and provide an independent
tracer of early star formation. Here, we utilize archival HST/ACS and JWST/NIRCam observations of
the nearby dwarf star-forming galaxy WLM to study RR Lyrae in JWST filters. We independently
identify RR Lyrae in HST and JWST imaging in order to evaluate JWST's efficacy at characterizing RR
Lyrae in the near-IR. We use an MCMC template-fitting technique to obtain periods, amplitudes, and
mean magnitudes from the RR Lyrae time-series data. The spatially overlapping HST and JWST
observations allow

## Multi-Vector Index Compression in Any Modality
**Authors:** Hanxiang Qin, Alexander Martin, Rohan Jha  
**Query:** autonomous agents open source  
**URL:** http://arxiv.org/abs/2602.21202v1

We study efficient multi-vector retrieval for late interaction in any modality. Late interaction has
emerged as a dominant paradigm for information retrieval in text, images, visual documents, and
videos, but its computation and storage costs grow linearly with document length, making it costly
for image-, video-, and audio-rich corpora. To address this limitation, we explore query-agnostic
methods for compressing multi-vector document representations under a constant vector budget. We
introduce four approaches for index compression: sequence resizing, memory tokens, hierarchical
pooling, and

## Aletheia tackles FirstProof autonomously
**Authors:** Tony Feng, Junehyuk Jung, Sang-hyun Kim  
**Query:** autonomous agents open source  
**URL:** http://arxiv.org/abs/2602.21201v1

We report the performance of Aletheia (Feng et al., 2026b), a mathematics research agent powered by
Gemini 3 Deep Think, on the inaugural FirstProof challenge. Within the allowed timeframe of the
challenge, Aletheia autonomously solved 6 problems (2, 5, 7, 8, 9, 10) out of 10 according to
majority expert assessments; we note that experts were not unanimous on Problem 8 (only). For full
transparency, we explain our interpretation of FirstProof and disclose details about our experiments
as well as our evaluation. Raw prompts and outputs are available at https://github.com/google-
deepmind/superhu

## Recursive Self-Aggregation Unlocks Deep Thinking in Large Language Models
**Authors:** Siddarth Venkatraman, Vineet Jain, Sarthak Mittal  
**Query:** self replicating systems  
**URL:** http://arxiv.org/abs/2509.26626v2

Test-time scaling methods improve the capabilities of large language models (LLMs) by increasing the
amount of compute used during inference to make a prediction. Inference-time compute can be scaled
in parallel by choosing among multiple independent solutions or sequentially through self-
refinement. We propose Recursive Self-Aggregation (RSA), a test-time scaling method inspired by
evolutionary methods that combines the benefits of both parallel and sequential scaling. Each step
of RSA refines a population of candidate reasoning chains through aggregation of subsets to yield a
population of i

## A Time-Varying and Covariate-Dependent Correlation Model for Multivariate Longitudinal Studies
**Authors:** Qingzhi Liu, Gen Li, Anastasia K. Yocum  
**Query:** self replicating systems  
**URL:** http://arxiv.org/abs/2602.21200v1

In multivariate longitudinal studies, associations between outcomes often exhibit time-varying and
individual level heterogeneity, motivating the modeling of correlations as an explicit function of
time and covariates. However, most existing methods for correlation analysis fail to simultaneously
capture the time-varying and covariate-dependent effects. We propose a Time-Varying and Covariate-
Dependent (TiVAC) correlation model that jointly allows covariate effects on correlation to change
flexibly and smoothly across time. TiVAC employs a bivariate Gaussian model where the covariate-
dependent

## Topological Floquet Green's function zeros
**Authors:** Elio J. König, Aditi Mitra  
**Query:** self replicating systems  
**URL:** http://arxiv.org/abs/2602.21199v1

Motivated by recent advances in digital quantum emulation using noisy intermediate-scale quantum
(NISQ) devices and an increased interest in topological Green's function zeros in condensed matter
systems, we here study Green's function zeros in topological Floquet systems. We concentrate on
interacting Kitaev-like Floquet chains (or equivalently transverse field Ising circuits) and
introduce Floquet Green's-function-based topological invariants for the corresponding symmetry class
BDI. In the vicinity of special points in the free fermion phase diagram and using tailor-made
interactions which

## XMorph: Explainable Brain Tumor Analysis Via LLM-Assisted Hybrid Deep Intelligence
**Authors:** Sepehr Salem Ghahfarokhi, M. Moein Esfahani, Raj Sunderraman  
**Query:** decentralized AI  
**URL:** http://arxiv.org/abs/2602.21178v1

Deep learning has significantly advanced automated brain tumor diagnosis, yet clinical adoption
remains limited by interpretability and computational constraints. Conventional models often act as
opaque ''black boxes'' and fail to quantify the complex, irregular tumor boundaries that
characterize malignant growth. To address these challenges, we present XMorph, an explainable and
computationally efficient framework for fine-grained classification of three prominent brain tumor
types: glioma, meningioma, and pituitary tumors. We propose an Information-Weighted Boundary
Normalization (IWBN) mech

## How much does context affect the accuracy of AI health advice?
**Authors:** Prashant Garg, Thiemo Fetzer  
**Query:** decentralized AI  
**URL:** http://arxiv.org/abs/2504.18310v2

Large language models (LLMs) are increasingly used to provide health advice, yet evidence on how
their accuracy varies across languages, topics and information sources remains limited. We assess
how linguistic and contextual factors affect the accuracy of AI-based health-claim verification. We
evaluated seven widely used LLMs on two datasets: (i) 1,975 legally authorised nutrition and health
claims from UK and EU regulatory registers translated into 21 languages; and (ii) 9,088 journalist-
vetted public-health claims from the PUBHEALTH corpus spanning COVID-19, abortion, politics and
general he

## Causal Claims in Economics
**Authors:** Prashant Garg, Thiemo Fetzer  
**Query:** decentralized AI  
**URL:** http://arxiv.org/abs/2501.06873v2

As economics scales, a key bottleneck is representing what papers claim in a comparable, aggregable
form. We introduce evidence-annotated claim graphs that map each paper into a directed network of
standardized economic concepts (nodes) and stated relationships (edges), with each edge labeled by
evidentiary basis, including whether it is supported by causal inference designs or by non-causal
evidence. Using a structured multi-stage AI workflow, we construct claim graphs for 44,852 economics
papers from 1980-2023. The share of causal edges rises from 7.7% in 1990 to 31.7% in 2020. Measures
of c

## Minimal loop currents in doped Mott insulators
**Authors:** Can Cui, Jing-Yu Zhao, Zheng-Yu Weng  
**Query:** local language models deployment  
**URL:** http://arxiv.org/abs/2602.21206v1

For the $t$-$J$ model, variational wave functions can generally be constructed based on an accurate
description of antiferromagnetism (AFM) at half-filling and an exact phase-string sign structure
under doping. The single-hole-doped and two-hole-doped states, as determined by variational Monte
Carlo (VMC) simulations, display sharply contrasting behaviors. The single-hole state constitutes a
``cat state'' that resonates strongly between a quasiparticle component and a local loop-current
component, with approximately equal weights. In the ground state, the quasiparticle spectral weight
$Z_{\mat

## Language Models use Lookbacks to Track Beliefs
**Authors:** Nikhil Prakash, Natalie Shapira, Arnab Sen Sharma  
**Query:** local language models deployment  
**URL:** http://arxiv.org/abs/2505.14685v3

How do language models (LMs) represent characters' beliefs, especially when those beliefs may differ
from reality? This question lies at the heart of understanding the Theory of Mind (ToM) capabilities
of LMs. We analyze LMs' ability to reason about characters' beliefs using causal mediation and
abstraction. We construct a dataset, CausalToM, consisting of simple stories where two characters
independently change the state of two objects, potentially unaware of each other's actions. Our
investigation uncovers a pervasive algorithmic pattern that we call a lookback mechanism, which
enables the L

## Test-Time Training with KV Binding Is Secretly Linear Attention
**Authors:** Junchen Liu, Sven Elflein, Or Litany  
**Query:** local language models deployment  
**URL:** http://arxiv.org/abs/2602.21204v1

Test-time training (TTT) with KV binding as sequence modeling layer is commonly interpreted as a
form of online meta-learning that memorizes a key-value mapping at test time. However, our analysis
reveals multiple phenomena that contradict this memorization-based interpretation. Motivated by
these findings, we revisit the formulation of TTT and show that a broad class of TTT architectures
can be expressed as a form of learned linear attention operator. Beyond explaining previously
puzzling model behaviors, this perspective yields multiple practical benefits: it enables principled
architectural

## Splittable Spanning Trees and Balanced Forests in Dense Random Graphs
**Authors:** David Gillman, Jacob Platnick, Dana Randall  
**Query:** humanitarian AI applications  
**URL:** http://arxiv.org/abs/2507.12707v3

We consider the probability that a spanning tree chosen uniformly at random from a graph can be
partitioned into a fixed number $k$ of trees of equal size by removing $k-1$ edges. In that case,
the spanning tree is called {\em splittable}. Splittable spanning trees are useful in algorithms for
sampling {\em balanced forests}, forests whose components are of equal size, and for sampling
partitions of a graph into components of equal size, with applications in redistricting, network
algorithms, and image decomposition. Cannon et al.~recently showed that spanning trees on grid and
grid-like graph

## Region of Interest Segmentation and Morphological Analysis for Membranes in Cryo-Electron Tomography
**Authors:** Xingyi Cheng, Julien Maufront, Aurélie Di Cicco  
**Query:** humanitarian AI applications  
**URL:** http://arxiv.org/abs/2602.21195v1

Cryo-electron tomography (cryo-ET) enables high resolution, three-dimensional reconstruction of
biological structures, including membranes and membrane proteins. Identification of regions of
interest (ROIs) is central to scientific imaging, as it enables isolation and quantitative analysis
of specific structural features within complex datasets. In practice, however, ROIs are typically
derived indirectly through full structure segmentation followed by post hoc analysis. This
limitation is especially apparent for continuous and geometrically complex structures such as
membranes, which are segme

## An Adaptive CMSA for Solving the Longest Filled Common Subsequence Problem with an Application in Audio Querying
**Authors:** Marko Djukanovic, Christian Blum, Aleksandar Kartelj  
**Query:** humanitarian AI applications  
**URL:** http://arxiv.org/abs/2509.12261v2

This paper addresses the Longest Filled Common Subsequence (LFCS) problem, a challenging NP-hard
problem with applications in bioinformatics, including gene mutation prediction and genomic data
reconstruction. Existing approaches, including exact, metaheuristic, and approximation algorithms,
have primarily been evaluated on small-sized instances, which offer limited insights into their
scalability. In this work, we introduce a new benchmark dataset with significantly larger instances
and demonstrate that existing datasets lack the discriminative power needed to meaningfully assess
algorithm pe

## Splittable Spanning Trees and Balanced Forests in Dense Random Graphs
**Authors:** David Gillman, Jacob Platnick, Dana Randall  
**Query:** mutual aid networks technology  
**URL:** http://arxiv.org/abs/2507.12707v3

We consider the probability that a spanning tree chosen uniformly at random from a graph can be
partitioned into a fixed number $k$ of trees of equal size by removing $k-1$ edges. In that case,
the spanning tree is called {\em splittable}. Splittable spanning trees are useful in algorithms for
sampling {\em balanced forests}, forests whose components are of equal size, and for sampling
partitions of a graph into components of equal size, with applications in redistricting, network
algorithms, and image decomposition. Cannon et al.~recently showed that spanning trees on grid and
grid-like graph

## Transfer Learning in Infinite Width Feature Learning Networks
**Authors:** Clarissa Lauditi, Blake Bordelon, Cengiz Pehlevan  
**Query:** mutual aid networks technology  
**URL:** http://arxiv.org/abs/2507.04448v2

We develop a theory of transfer learning in infinitely wide neural networks under gradient flow that
quantifies when pretraining on a source task improves generalization on a target task. We analyze
both (i) fine-tuning, when the downstream predictor is trained on top of source-induced features and
(ii) a jointly rich setting, where both pretraining and downstream tasks can operate in a feature
learning regime, but the downstream model is initialized with the features obtained after pre-
training. In this setup, the summary statistics of randomly initialized networks after a rich pre-
training a

## 823-OLT @ BUET DL Sprint 4.0: Context-Aware Windowing for ASR and Fine-Tuned Speaker Diarization in Bengali Long Form Audio
**Authors:** Ratnajit Dhar, Arpita Mallik  
**Query:** mutual aid networks technology  
**URL:** http://arxiv.org/abs/2602.21183v1

Bengali, despite being one of the most widely spoken languages globally, remains underrepresented in
long form speech technology, particularly in systems addressing transcription and speaker
attribution. We present frameworks for long form Bengali speech intelligence that address automatic
speech recognition using a Whisper Medium based model and speaker diarization using a finetuned
segmentation model. The ASR pipeline incorporates vocal separation, voice activity detection, and a
gap aware windowing strategy to construct context preserving segments for stable decoding. For
diarization, a pre
